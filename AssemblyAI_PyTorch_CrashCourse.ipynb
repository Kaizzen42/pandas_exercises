{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9Uey5Qne38ZciSksZWbyl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kaizzen42/pandas_exercises/blob/main/AssemblyAI_PyTorch_CrashCourse.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H2zNl25c6iF2"
      },
      "outputs": [],
      "source": [
        "# https://www.youtube.com/watch?v=OIenNRt2bjg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "IHGOFddt6tax"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets Try to fit a linear regression model to the function\n",
        "f(x) = 2 * x"
      ],
      "metadata": {
        "id": "lwxqSPfN-WuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.tensor([1,2,3,4,5,6,7,8], dtype=torch.float32)\n",
        "Y = torch.tensor([2,4,6,8,10,12,14,16], dtype=torch.float32)\n",
        "\n",
        "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# Model output\n",
        "def forward(x):\n",
        "  return w * x\n",
        "# Loss = MSE\n",
        "def loss(y, y_pred):\n",
        "  return ((y_pred - y) **2).mean()\n",
        "\n",
        "X_test = 5.0\n",
        "\n",
        "print(f\"Prediction before training: f({X_test}) = {forward(X_test).item():.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoO10MYR-c2u",
        "outputId": "bc474ddb-75bd-43c4-9f67-826cb73a69b2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction before training: f(5.0) = 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "learning_rate = 0.01\n",
        "n_epochs = 25\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  # Forward Pass\n",
        "  y_pred = forward(X)\n",
        "  # Loss computation\n",
        "  l = loss(Y, y_pred)\n",
        "  # Backpropagation\n",
        "  l.backward()\n",
        "\n",
        "  # Update weights\n",
        "  # w.data = w.data - lr * w.grad\n",
        "  with torch.no_grad():\n",
        "    w -= learning_rate * w.grad\n",
        "  w.grad.zero_()\n",
        "\n",
        "  print(f\"Epoch {epoch+1}: w = {w.item():.3f}, Loss = {l}\")\n",
        "  print(f\"Prediction during training, after {epoch+1} epochs: f({X_test}) = {forward(X_test).item():.3f}\")\n",
        "print(f\"Prediction After training: f({X_test}) = {forward(X_test).item():.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHU4V8kJ_Qwk",
        "outputId": "09dffec3-2778-4653-ef1e-6c881a43b493"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: w = 1.020, Loss = 102.0\n",
            "Prediction during training, after 1 epochs: f(5.0) = 5.100\n",
            "Epoch 2: w = 1.520, Loss = 24.49020004272461\n",
            "Prediction during training, after 2 epochs: f(5.0) = 7.599\n",
            "Epoch 3: w = 1.765, Loss = 5.880098819732666\n",
            "Prediction during training, after 3 epochs: f(5.0) = 8.824\n",
            "Epoch 4: w = 1.885, Loss = 1.4118115901947021\n",
            "Prediction during training, after 4 epochs: f(5.0) = 9.424\n",
            "Epoch 5: w = 1.944, Loss = 0.33897578716278076\n",
            "Prediction during training, after 5 epochs: f(5.0) = 9.718\n",
            "Epoch 6: w = 1.972, Loss = 0.0813881903886795\n",
            "Prediction during training, after 6 epochs: f(5.0) = 9.862\n",
            "Epoch 7: w = 1.986, Loss = 0.019541269168257713\n",
            "Prediction during training, after 7 epochs: f(5.0) = 9.932\n",
            "Epoch 8: w = 1.993, Loss = 0.004691871348768473\n",
            "Prediction during training, after 8 epochs: f(5.0) = 9.967\n",
            "Epoch 9: w = 1.997, Loss = 0.0011265306966379285\n",
            "Prediction during training, after 9 epochs: f(5.0) = 9.984\n",
            "Epoch 10: w = 1.998, Loss = 0.0002704716462176293\n",
            "Prediction during training, after 10 epochs: f(5.0) = 9.992\n",
            "Epoch 11: w = 1.999, Loss = 6.494270928669721e-05\n",
            "Prediction during training, after 11 epochs: f(5.0) = 9.996\n",
            "Epoch 12: w = 2.000, Loss = 1.5594378055538982e-05\n",
            "Prediction during training, after 12 epochs: f(5.0) = 9.998\n",
            "Epoch 13: w = 2.000, Loss = 3.7428901578095974e-06\n",
            "Prediction during training, after 13 epochs: f(5.0) = 9.999\n",
            "Epoch 14: w = 2.000, Loss = 8.987138926386251e-07\n",
            "Prediction during training, after 14 epochs: f(5.0) = 10.000\n",
            "Epoch 15: w = 2.000, Loss = 2.1599277033601538e-07\n",
            "Prediction during training, after 15 epochs: f(5.0) = 10.000\n",
            "Epoch 16: w = 2.000, Loss = 5.1823555224927986e-08\n",
            "Prediction during training, after 16 epochs: f(5.0) = 10.000\n",
            "Epoch 17: w = 2.000, Loss = 1.2426690787492589e-08\n",
            "Prediction during training, after 17 epochs: f(5.0) = 10.000\n",
            "Epoch 18: w = 2.000, Loss = 3.004425153108059e-09\n",
            "Prediction during training, after 18 epochs: f(5.0) = 10.000\n",
            "Epoch 19: w = 2.000, Loss = 7.320810624378282e-10\n",
            "Prediction during training, after 19 epochs: f(5.0) = 10.000\n",
            "Epoch 20: w = 2.000, Loss = 1.7278267705478356e-10\n",
            "Prediction during training, after 20 epochs: f(5.0) = 10.000\n",
            "Epoch 21: w = 2.000, Loss = 4.430411593148165e-11\n",
            "Prediction during training, after 21 epochs: f(5.0) = 10.000\n",
            "Epoch 22: w = 2.000, Loss = 8.890665981198254e-12\n",
            "Prediction during training, after 22 epochs: f(5.0) = 10.000\n",
            "Epoch 23: w = 2.000, Loss = 1.7408297026122455e-12\n",
            "Prediction during training, after 23 epochs: f(5.0) = 10.000\n",
            "Epoch 24: w = 2.000, Loss = 5.204725539442734e-13\n",
            "Prediction during training, after 24 epochs: f(5.0) = 10.000\n",
            "Epoch 25: w = 2.000, Loss = 0.0\n",
            "Prediction during training, after 25 epochs: f(5.0) = 10.000\n",
            "Prediction After training: f(5.0) = 10.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, let's train a real model on MNist data"
      ],
      "metadata": {
        "id": "y4bniaLVCJKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1], [2], [3], [4], [5], [6], [7], [8]] , dtype=torch.float32)\n",
        "Y = torch.tensor([[2], [4], [6], [8], [10], [12], [14], [16]] , dtype=torch.float32)\n",
        "\n",
        "n_samples, n_features = X.shape\n",
        "print(f\"{n_samples=}, {n_features=}\")\n",
        "\n",
        "X_test = torch.tensor([5], dtype=torch.float32)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr-YY_-SCIiI",
        "outputId": "cbb8e6b6-f7a2-443d-ae8f-79a1ca9e277d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_samples=8, n_features=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegression(nn.Module):\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super(LinearRegression, self).__init__()\n",
        "    self.lin = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lin(x)\n",
        "\n",
        "input_size, output_size = n_features, n_features\n",
        "model = LinearRegression(input_size, output_size)\n",
        "\n",
        "n_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "loss = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  y_pred = model(X)\n",
        "  l = loss(Y, y_pred)\n",
        "\n",
        "  l.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "  if (epoch+1) %10 == 0:\n",
        "    w, b = model.parameters()\n",
        "    print(f\"Epoch {epoch+1}, w = {w[0][0].item()},  Loss = {l.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc4xx9zRAZmD",
        "outputId": "9844ee6a-b5fc-4898-9c0a-ea616c976335"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, w = 0.7396301031112671,  Loss = 52.14570236206055\n",
            "Epoch 20, w = 1.2876096963882446,  Loss = 17.70801544189453\n",
            "Epoch 30, w = 1.606745958328247,  Loss = 6.021154403686523\n",
            "Epoch 40, w = 1.79257071018219,  Loss = 2.0550098419189453\n",
            "Epoch 50, w = 1.9007362127304077,  Loss = 0.7089624404907227\n",
            "Epoch 60, w = 1.963661551475525,  Loss = 0.2520769536495209\n",
            "Epoch 70, w = 2.000232696533203,  Loss = 0.09693726897239685\n",
            "Epoch 80, w = 2.021451950073242,  Loss = 0.044197920709848404\n",
            "Epoch 90, w = 2.0337281227111816,  Loss = 0.026210706681013107\n",
            "Epoch 100, w = 2.040794849395752,  Loss = 0.020017435774207115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eagdJp2-RpwU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}